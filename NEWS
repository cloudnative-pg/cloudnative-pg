Cloud Native PostgreSQL  - History of user-visible changes
Copyright (C) 2019-2020 EnterpriseDB.

Version 0.7.0 - 31 Dec 2020

- Support `pg_rewind` if needed following a failover or switchover to
  let the former primary act as a standby
- Add persistent volume expansion support, if permitted by the storage class
- Enhance metrics exporter for PostgreSQL
- Add support for Kubernetes version 1.20
- Drop support for Kubernetes version 1.15
- Refactor E2E tests, including conversion to Github actions
- Bug fixes and improvements

Version 0.6.0 - 4 Dec 2020

- Add Point-In-Time Recovery based on timestamp, target name, or transaction
  Id, as well as the specification of the timeline, through a new bootstrap
  method option called `recoveryTarget`
- Add Synchronous Streaming Replication support through the `minSyncReplicas`
  and `maxSyncReplicas` cluster options, defining respectively the expected
  minimum and maximum number of synchronous standby servers at any time (disabled
  by default)
- Configure `initdb` options for the bootstrap of an empty cluster (`initDb`)
- Extend the instance manager with a new framework for the export of metrics
  for Prometheus - currently supporting pg_stat_archiver only
- Use Kubernetes jobs instead of init containers to perform cluster
  initialization procedures (including standby creation and recovery) and
  improve their observability
- Record Kubernetes events to be used by `kubectl describe` and
  `kubectl get events`
- Introduce Kubernetes expectations for Pods, PVCs, and Jobs to prevent race
  conditions
- Set `application_name` in PostgreSQL to the name of the Pod/instance
- The `fullRecovery` bootstrap mode has been renamed to `recovery`
  to address also Point-In-Time Recovery
- Bug fixes and improvements

Version 0.5.0 - 20 Nov 2020

- Automated provisioning of an independent Certification Authority (CA) for
  each PostgreSQL cluster
- Transparent and native support for TLS/SSL connections to encrypt
  client/server communications
- Improve the security of the standby streaming replication channel through:
    - a dedicated and fixed database user called `streaming_replica` with sole
      `REPLICATION` privileges
    - an automatically managed X.509 TLS certificate signed by the cluster
      Certification Authority to authenticate the `streaming_replica` user
- Improve PostgreSQL configuration capability through:
    - a mutating webhook that prevents users from changing those parameters
      that are directly managed by the operator
    - a defaulting webhook that integrates the users' supplied configuration
      options with default values in the cluster state
    - automated management of the PostgreSQL instances reload and restart
- Enable custom and independent configuration of a PostgreSQL cluster following
  a recovery from a backup
- Convey the current status of the cluster (i.e. healthy, failover in progress,
  switchover in progress)
- API change from k8s.2ndq.io to k8s.enterprisedb.io

Version 0.4.0 - 5 Nov 2020

- Support for full recovery from a backup
- Add `bootstrap` section to configure how to initiate a cluster: `initDB`
  or `fullRecovery`
- Introduce defaulting and validating webhooks
- Simplify configuration (convention over configuration)
- Constrain rolling upgrades to the same PostgreSQL major version
- End-to-end tests run on GKE, AKS and GKS
- Documentation improvements
- Bug fixes and minor improvements

Version 0.3.0 - 25 Sep 2020

- Support for PostgreSQL 13
- Remove `emptyDir` volume storage support
- Node maintenance support for PostgreSQL clusters with local storage through
  the `nodeMaintenanceWindow` parameter
- Improve PostgreSQL configuration management through the usage of a dictionary
  supporting default, required and fixed values
- Use MD5 as authentication method for inter-cluster communication, with
  automated password creation in a secret
- Remove need for "trust" authentication method
- `spec.postgresql.pg_hba` is now optional, defaulting to MD5 authentication
  required for communication between Pods and `peer` for in-Pod communication
- Remove "unusable" annotation support, now PVC can just be removed followed by
  a deletion of the corresponding Pod
- Bug fixes and minor improvements
- Update from an earlier version not supported

Version 0.2.0 - 11 Aug 2020

- PostgreSQL 10 and 11 are now supported, in addition to PostgreSQL 12
- Usage of UBI as base image of the operator (OpenShift support)
- New Backup and ScheduledBackup CRD, allowing users to take a physical backup
  of the cluster in an object store that complies with the S3 protocol (such as
  AWS S3, MinIO, MinIO Gateway)
- Support for WAL archiving to an object store that complies with the S3 protocol
- Improvements in the E2e tests infrastructure
- Bug fixes and minor improvements

Version 0.1.0 -  3 Apr 2020

- Reuse of existing persistent storage with Pods (required for rolling updates)
- Independence between operator container image and PostgreSQL container image
  (required by rolling updates) - this enables usage of Community PostgreSQL images
- Rolling updates for the update of the operator and the entire cluster
  to a new version of PostgreSQL, by updating all the replicas first;
  switchover can be entirely managed by Kubernetes once replicas have been
  updated (`unsupervised` option), or manually triggered by the user (`supervised` option)
- Check framework for update-in-progress of a Pod
- Improvements in cluster status information
- E2E tests for Kubernetes 1.18
- E2E performance tests for failover (< 5 seconds)
- Improvements in E2E tests for switchover
- Support for PostgreSQL's `cluster_name` GUC
- New documentation section `Exposing Postgres services`
- New documentation section `Security`

Version 0.0.1 -  5 Mar 2020

Prototype of PostgreSQL Operator with:

- PostgreSQL 12.2 container image
- Self-Healing capability, through:
    - failover of the primary instance, by promoting the most aligned replica
    - automated recreation of a replica
- Planned switchover of the primary instance, by promoting a selected replica
- Scale up/down capabilities
- Definition of an arbitrary number of instances (minimum 1 - one primary server)
- Definition of the *read-write* service, to connect your applications to the only primary server of the cluster
- Definition of the *read-only* service, to connect your applications to any of the instances for read workloads
- Support for Local Persistent Volumes with PVC templates
- Standard output logging of PostgreSQL error messages
