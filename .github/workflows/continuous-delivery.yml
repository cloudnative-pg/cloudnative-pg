name: continuous-delivery

on:
  push:
  pull_request:
  workflow_dispatch:
    inputs:
      depth:
        description: 'Depth (push, pull_request, main, schedule)'
        required: true
        default: 'main'
      limit:
        description: 'Limit to the specified engines list (local, eks, aks, gke)'
        required: false
  schedule:
    - cron:  '0 1 * * *'

env:
  GOLANG_VERSION: "1.15.x"
  GOLANGCI_LINT_VERSION: "v1.40"
  KUBEBUILDER_VERSION: "2.3.1"
  KIND_VERSION: "v0.11.0"

defaults:
  run:
    shell: 'bash -Eeuo pipefail -x {0}'

jobs:

  duplicate_runs:
    runs-on: ubuntu-20.04
    name: Skip duplicate runs
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
    steps:
      - id: skip_check
        uses: fkirc/skip-duplicate-actions@v3.4.0
        with:
          concurrent_skipping: 'same_content'
          skip_after_successful_duplicate: 'true'
          paths_ignore: '["README.md", "docs/**"]'
          do_not_skip: '["pull_request", "workflow_dispatch", "schedule"]'

  golangci:
    name: Run linters
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.4
      -
        name: Run golangci-lint
        uses: golangci/golangci-lint-action@v2.5.2
        with:
          version: ${{ env.GOLANGCI_LINT_VERSION }}
          args: --timeout 4m

  shellcheck:
    name: Run shellcheck linter
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    env:
        SHELLCHECK_OPTS: -a -S style
    steps:
    -
      uses: actions/checkout@v2.3.4
    -
      name: Run ShellCheck
      uses: ludeeus/action-shellcheck@1.1.0

  tests:
    name: Run unit tests
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.4
      -
        name: Install Go
        uses: actions/setup-go@v2
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      # Install kubebuilder that is a requirement to run tests
      -
        name: Install Kubebuilder
        run: |
          mkdir -p /tmp/kubebuilder
          curl -sSL https://go.kubebuilder.io/dl/${{ env.KUBEBUILDER_VERSION }}/$(go env GOOS)/$(go env GOARCH) | tar --strip-components=1 -xz -C /tmp/kubebuilder
          sudo mv /tmp/kubebuilder /usr/local/
      -
        name: Run unit tests
        run:
          make test

  apidoc:
    name: Verify API doc is up to date
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
    - name: Checkout code
      uses: actions/checkout@v2.3.4

    - name: Install Go
      uses: actions/setup-go@v2.1.3
      with:
        go-version: ${{ env.GOLANG_VERSION }}

    - name: Run make apidoc
      run: |
        make apidoc

    - name: Verify apidoc changes
      run: |
        apidoc_file_path='docs/src/api_reference.md'
        if git status --porcelain $apidoc_file_path | grep '^ M'; then
          echo "The API documentation doesn't reflect the current API. Please run make apidoc."
          exit 1
        fi

  crd:
    name: Verify CRD is up to date
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v2.3.4

      - name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}

      - name: Run make manifests
        run: |
          make manifests

      - name: Check CRD manifests are up to date
        run: |
          crd_path='config/crd'
          if git status --porcelain $crd_path | grep '^ M'; then
            echo "The CRD manifests do not reflect the current API. Please run make manifests."
            exit 1
          fi

  buildx:
    name: Build containers
    needs:
      - golangci
      - shellcheck
      - tests
      - apidoc
      - crd
      - duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    outputs:
      image: ${{ steps.image-meta.outputs.image }}
    steps:
      -
        name: Checkout
        uses: actions/checkout@v2.3.4
        with:
          # To identify the commit we need the history and all teh tags.
          fetch-depth: 0
      -
        name: Build meta
        id: build-meta
        run: |
          # By default, set the "testing" target repository on Quay.io
          # (every built container is pushed there)
          images='quay.io/enterprisedb/cloud-native-postgresql-testing'
          tags=''
          labels=''
          # In case we have a tag, add the main target repository
          if [ "${GITHUB_REF#refs/tags/}" != "${GITHUB_REF}" ]
          then
            images="${images},quay.io/enterprisedb/cloud-native-postgresql,enterprisedb/cloud-native-postgresql"
          fi
          # In case of commit on the "main" branch or tag, set the "latest"
          # label to the container image on the target repositories.
          # Otherwise set expiration to 7 days.
          if [ "${GITHUB_REF#refs/heads/}" == main ] || [ "${GITHUB_REF#refs/tags/}" != "${GITHUB_REF}" ]
          then
            tags='latest'
          else
            labels='quay.expires-after=7d'
          fi
          commit_sha=${{ github.event.pull_request.head.sha || github.sha }}
          commit_date=$(git log -1 --pretty=format:'%ad' --date short "${commit_sha}")
          # use git describe to get the nearest tag and use that to build the version (e.g. 1.4.0+dev24 or 1.4.0)
          commit_version=$(git describe --tags --match 'v*' "${commit_sha}"| sed -e 's/^v//; s/-g[0-9a-f]\+$//; s/-\([0-9]\+\)$/+dev\1/')
          commit_short=$(git rev-parse --short "${commit_sha}")
          echo "::set-output name=images::${images}"
          echo "::set-output name=tags::${tags}"
          echo "::set-output name=labels::${labels}"
          echo "::set-output name=date::${commit_date}"
          echo "::set-output name=version::${commit_version}"
          echo "::set-output name=commit::${commit_short}"
      -
        name: Docker meta
        id: docker-meta
        uses: docker/metadata-action@v3
        with:
          images: ${{ steps.build-meta.outputs.images }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=match,pattern=v(\d.\d.\d),group=1,priority=1000
      -
        name: Set up QEMU
        uses: docker/setup-qemu-action@v1
      -
        name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v1
      -
        name: Login to quay.io
        uses: docker/login-action@v1
        with:
          registry: quay.io/enterprisedb
          username: ${{ secrets.QUAY_USERNAME }}
          password: ${{ secrets.QUAY_TOKEN }}
      -
        name: Login to Docker Hub
        uses: docker/login-action@v1
        with:
          username: ${{ secrets.DOCKER_HUB_USER }}
          password: ${{ secrets.DOCKER_HUB_SECRET }}
      -
        name: Build and push
        uses: docker/build-push-action@v2.5.0
        with:
          # Available architecture on UBI8 are: linux/amd64, linux/arm64, linux/ppc64le
          platforms: linux/amd64
          push: true
          build-args: |
            DATE=${{ steps.build-meta.outputs.date }}
            COMMIT=${{ steps.build-meta.outputs.commit }}
            VERSION=${{ steps.build-meta.outputs.version }}
          tags: ${{ steps.docker-meta.outputs.tags }}
          labels: ${{ steps.build-meta.outputs.labels }}
      -
        name: Image Meta
        id: image-meta
        env:
          TAGS: ${{ steps.docker-meta.outputs.tags }}
        run: |
          # If there is more than one tag, take the first one
          # TAGS could be separated by newlines or commas
          image=$(sed -n '1{s/,.*//; p}' <<< "$TAGS")
          echo "::set-output name=image::${image}"

  trigger-ocp:
    name: Trigger OCP bundle
    needs:
      - golangci
      - shellcheck
      - tests
      - apidoc
      - crd
      - duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
      - name: Repository Dispatch
        uses: peter-evans/repository-dispatch@v1.1.3
        with:
          token: ${{ secrets.REPO_GHA_PAT }}
          repository: enterprisedb/cloud-native-postgresql-ocp-certified
          event-type: cnp-trigger
          client-payload: '{"upstream_commit": "${{ github.event.pull_request.head.sha || github.sha }}"}'

  generate-jobs:
    name: Generate jobs for E2E tests
    needs:
      - buildx
      - duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    outputs:
      image: ${{ needs.buildx.outputs.image }}
      localMatrix: ${{ steps.generate-jobs.outputs.localMatrix }}
      localEnabled: ${{ steps.generate-jobs.outputs.localEnabled }}
      eksMatrix: ${{ steps.generate-jobs.outputs.eksMatrix }}
      eksEnabled: ${{ steps.generate-jobs.outputs.eksEnabled }}
      aksMatrix: ${{ steps.generate-jobs.outputs.aksMatrix }}
      aksEnabled: ${{ steps.generate-jobs.outputs.aksEnabled }}
      gkeMatrix: ${{ steps.generate-jobs.outputs.gkeMatrix }}
      gkeEnabled: ${{ steps.generate-jobs.outputs.gkeEnabled }}
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.4
      -
        id: generate-jobs
        name: Generate Jobs
        shell: bash
        run: |
          python .github/e2e-matrix-generator.py \
            -m '${{ github.event.inputs.depth || github.event_name }}' \
            -l '${{ github.event.inputs.limit }}'

  e2e-local:
    name: Run E2E on local executors
    if: ${{ needs.generate-jobs.outputs.localEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
    needs:
      - generate-jobs
      - duplicate_runs
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.generate-jobs.outputs.localMatrix) }}
    runs-on: ubuntu-20.04
    env:
      K8S_VERSION: "${{ matrix.k8s_version }}"
      POSTGRES_IMG: "${{ matrix.postgres_img }}"
      E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

      DOCKER_SERVER: quay.io/enterprisedb
      DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

      DEBUG: "true"
      BUILD_IMAGE: "false"
      CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
      E2E_DEFAULT_STORAGE_CLASS: standard
      LOG_DIR: ${{ github.workspace }}/kind-logs/
      DOCKER_REGISTRY_MIRROR: https://mirror.gcr.io
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.4
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name: Clean up all the left overs in docker
        run:
          docker system prune -a -f
      -
        name: Prepare the environment
        run: |
          sudo apt-get update
          sudo apt-get install -y gettext-base
          sudo hack/setup-cluster.sh prepare /usr/local/bin
      -
        name: Run Kind End-to-End tests
        run:
          make e2e-test-kind
      -
        name: Archive Kind logs
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: kind-logs-${{ matrix.id }}
          path: kind-logs/
          retention-days: 7
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore

  e2e-aks:
    name: Run E2E on Microsoft AKS
    if: ${{ needs.generate-jobs.outputs.aksEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
    needs:
      - generate-jobs
      - duplicate_runs
    strategy:
      fail-fast: false
      max-parallel: 15
      matrix:
         ${{ fromJSON(needs.generate-jobs.outputs.aksMatrix) }}
    runs-on: ubuntu-20.04
    env:
      K8S_VERSION: "${{ matrix.k8s_version }}"
      POSTGRES_IMG: "${{ matrix.postgres_img }}"
      E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

      DOCKER_SERVER: quay.io/enterprisedb
      DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

      DEBUG: "true"
      BUILD_IMAGE: "false"
      CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
      E2E_DEFAULT_STORAGE_CLASS: rook-ceph-block

      # Disable upgrade test in AKS E2E
      # CNP 0.7.0 is not compatible with the latest rook installation that is
      # required for testing on AKS, hence we cannot test the upgrade there.
      TEST_UPGRADE_TO_V1: "false"
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.4
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name:  Install ginkgo
        run: |
          go install github.com/onsi/ginkgo/ginkgo
      -
        name: Azure Login
        uses: azure/login@v1.3.0
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      -
        name: Install kubectl
        uses: azure/setup-kubectl@v1
        with:
          version: v${{ env.K8S_VERSION }}
      -
        name: Create AKS cluster
        run: |
            az extension add --name aks-preview
            az account set --subscription "Cloud Native Development"
            az aks create --resource-group ${{ secrets.AZURE_RESOURCEGROUP }} \
              --name ${{ secrets.AZURE_RESOURCENAME }}-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' ) \
              --node-count 3 -k v${K8S_VERSION} --generate-ssh-keys --enable-addons monitoring \
              --workspace-resource-id ${{ secrets.AZURE_WORKSPACE_RESOURCE_ID }} \
              --aks-custom-headers EnableAzureDiskFileCSIDriver=true
            az aks get-credentials --resource-group ${{ secrets.AZURE_RESOURCEGROUP }} \
              --name ${{ secrets.AZURE_RESOURCENAME }}-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' )
      -
        # Azure is slow in provisioning disks, and we can't wait two minutes
        # every time we create a pod, otherwise all the tests will time out.
        # We set up a few large disks now, we run Rook on top of them and we
        # use rook to get the small PV we use in the tests.
        # It can still take a while to deploy rook.
        name: Set up Rook
        run: |
          if [ "${K8S_VERSION}" \> "1.20.1" ]; then
            STORAGECLASSNAME=default
          else
            STORAGECLASSNAME=managed-csi
          fi
          GO111MODULE=on go get github.com/mikefarah/yq/v4
          ROOK_BASE_URL=https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph #wokeignore:rule=master
          kubectl apply -f ${ROOK_BASE_URL}/crds.yaml
          kubectl apply -f ${ROOK_BASE_URL}/common.yaml
          kubectl apply -f ${ROOK_BASE_URL}/operator.yaml
          curl ${ROOK_BASE_URL}/cluster-on-pvc.yaml | \
            sed '/^ *#/d;/^ *$/d' | \
            yq e ".spec.storage.storageClassDeviceSets[].volumeClaimTemplates[].spec.resources.requests.storage = \"50Gi\" |
              .spec.storage.storageClassDeviceSets[].volumeClaimTemplates[].spec.storageClassName = \"${STORAGECLASSNAME}\" |
              .spec.mon.volumeClaimTemplate.spec.storageClassName = \"${STORAGECLASSNAME}\" " - | \
            kubectl apply -f -
          ITER=0
          MAX_ITER=120
          while true; do
            output=$( kubectl get deploy -n rook-ceph -l app=rook-ceph-osd --no-headers -o name )
            if [[ $(wc -w <<< $output)  == 3 ]]; then
              break
            fi

            (( ++ITER ))
            if [[ ${ITER} -ge ${MAX_ITER} ]]; then
              echo "Time out waiting for Rook OSDs deployments"
              exit 1
            fi
            echo "$(wc -w <<< $output) out of 3 Rook OSDs deployments exist, waiting 10s (${ITER}/${MAX_ITER})."
            sleep 10
          done
          echo "Waiting for Rook OSDs to be available"
          kubectl wait deploy -n rook-ceph --for condition=available --timeout 480s -l app=rook-ceph-osd
          kubectl apply -f ${ROOK_BASE_URL}/csi/rbd/storageclass.yaml
      -
        name: Run E2E tests
        run: hack/e2e/run-e2e.sh
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore
      -
        name: Clean up
        if: always()
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az account set --subscription "Cloud Native Development"
            az aks delete --resource-group ${{ secrets.AZURE_RESOURCEGROUP }} -y \
              --name ${{ secrets.AZURE_RESOURCENAME }}-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' )

  e2e-eks:
    name: Run E2E on Amazon EKS
    if: ${{ needs.generate-jobs.outputs.eksEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
    needs:
      - generate-jobs
      - duplicate_runs
    strategy:
      fail-fast: false
      matrix:
         ${{ fromJSON(needs.generate-jobs.outputs.eksMatrix) }}
    runs-on: ubuntu-20.04
    env:
      K8S_VERSION: "${{ matrix.k8s_version }}"
      POSTGRES_IMG: "${{ matrix.postgres_img }}"
      E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

      DOCKER_SERVER: quay.io/enterprisedb
      DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

      DEBUG: "true"
      BUILD_IMAGE: "false"
      CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
      E2E_DEFAULT_STORAGE_CLASS: gp2

      AWS_REGION: eu-central-1
    steps:
      -
        name: Set cluster name
        run: |
          echo "CLUSTER_NAME=cnp-test-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' )" >> $GITHUB_ENV
      -
        name: Checkout code
        uses: actions/checkout@v2.3.4
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name:  Install ginkgo
        run: |
          go install github.com/onsi/ginkgo/ginkgo
      -
        name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      -
        name: Install eksctl
        run: |
          mkdir -p "$HOME/.local/bin"
          curl -sL "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" \
            | tar xz -C $HOME/.local/bin
          echo "$HOME/.local/bin" >> $GITHUB_PATH
      -
        name: Configure EKS setup
        run: |
          envsubst < hack/e2e/eks-cluster.yaml.template > hack/e2e/eks-cluster.yaml
      -
        name: Setup EKS
        run: |
          eksctl create cluster -f hack/e2e/eks-cluster.yaml
      -
        name: Setup log archiving via fluentd and insights
        run: |
          curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluentd-quickstart.yaml \
            | sed "s/{{cluster_name}}/${{ env.CLUSTER_NAME }}/;s/{{region_name}}/${{ env.AWS_REGION }}/" \
            | kubectl apply -f -
      -
        name: Run E2E tests
        run: hack/e2e/run-e2e.sh
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore
      -
        name: Clean up
        if: always()
        run: |
          while true; do
              output=$( eksctl delete cluster -n ${{ env.CLUSTER_NAME }} -r "${{ env.AWS_REGION }}" --wait 2>&1 )
              status=$?
              if [[ $status == 0 ]]; then
                  echo "EKS cluster deleted"
                  break
              fi
              if ( grep "ResourceNotFoundException: No cluster found for name: ${{ env.CLUSTER_NAME }}" <<< "$output" ); then
                  echo "EKS cluster doesn't exist, nothing to remove"
                  break
              fi
              echo "Failed deleting cluster ${{ env.CLUSTER_NAME }}, retrying"
              sleep 5
          done

  e2e-gke:
    name: Run E2E on Google GKE
    if: ${{ needs.generate-jobs.outputs.gkeEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
    needs:
      - generate-jobs
      - duplicate_runs
    strategy:
      fail-fast: false
      max-parallel: 10
      matrix:
        ${{ fromJSON(needs.generate-jobs.outputs.gkeMatrix) }}
    runs-on: ubuntu-20.04
    env:
      K8S_VERSION: "${{ matrix.k8s_version }}"
      POSTGRES_IMG: "${{ matrix.postgres_img }}"
      E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

      DOCKER_SERVER: quay.io/enterprisedb
      DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

      DEBUG: "true"
      BUILD_IMAGE: "false"
      CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
      E2E_DEFAULT_STORAGE_CLASS: standard

      ZONE: europe-west3-a
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.4
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name:  Install ginkgo
        run: |
          go install github.com/onsi/ginkgo/ginkgo
      -
        name: Set cluster name
        run: |
          # GKE cluster names rules:
          # only lowercase alphanumerics and '-' allowed, must start with a letter and end with an alphanumeric,
          # and must be no longer than 40 characters
          # We need to shorten the name and lower the case
          SHORT_ID=$( echo ${{ matrix.id }} | tr -d '_.-' | tr '[:upper:]' '[:lower:]')
          echo "CLUSTER_NAME=cnp-test-${{ github.run_number }}-${SHORT_ID}" >> $GITHUB_ENV
      -
        name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@master #wokeignore:rule=master
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT }}
          export_default_credentials: true
      -
        name: Install kubectl
        run: gcloud components install --quiet kubectl
      -
        name: Create GKE cluster
        run: |
          # We may go over the amount of API requests allowed
          # by Google when creating all the clusters at the same time.
          # We give a few attempts at creating the cluster before giving up
          for i in `seq 1 5`; do
            if gcloud container clusters create ${{ env.CLUSTER_NAME }} \
              --num-nodes=3 \
              --cluster-version=${{ env.K8S_VERSION }} \
              --zone=${{ env.ZONE }} \
              --disk-size=20 \
              --machine-type=e2-standard-2
            then
              exit 0
            fi
            echo "Couldn't create the cluster. Retrying in 100s."
            sleep 100
          done
          echo "Couldn't create the cluster. Failing."
          exit 1
      -
        name: Get GKE kubeconfig credentials
        uses: google-github-actions/get-gke-credentials@main
        with:
          cluster_name: ${{ env.CLUSTER_NAME }}
          location: ${{ env.ZONE }}
          credentials: ${{ secrets.gcp_credentials }}
          use_auth_provider: true
      -
        name: Run E2E tests
        run: hack/e2e/run-e2e.sh
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore
      -
        name: Clean up
        if: always()
        run: |
          gcloud container clusters delete ${{ env.CLUSTER_NAME }} --zone=${{ env.ZONE }} --quiet
          # Disks are not automatically deleted when the cluster is removed and
          # their name only contains the run number, so we can't find the actual cluster from
          # the matrix that created them. We delete all the disks of a run that are not
          # owned by anyone, without worrying to much if some other job deleted them first.
          IDS=$(gcloud compute disks list --filter="name~cnp-test-${{github.run_number}} AND zone:${{env.ZONE}} AND -users:*" --format="value(id)")
          for ID in ${IDS}
          do
            gcloud compute disks delete --zone "${{env.ZONE}}" --quiet "${ID}" || true
          done
