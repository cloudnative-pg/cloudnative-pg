name: continuous-delivery

on:
  push:
    branches:
      - '**'
  pull_request:
  workflow_dispatch:
    inputs:
      depth:
        description: 'Depth (push, pull_request, main, schedule)'
        required: true
        default: 'main'
      limit:
        description: 'Limit to the specified engines list (local, eks, aks, gke, rke)'
        required: false
  schedule:
    - cron:  '0 1 * * *'

env:
  GOLANG_VERSION: "1.17.x"
  GOLANGCI_LINT_VERSION: "v1.40"
  KUBEBUILDER_VERSION: "2.3.1"
  KIND_VERSION: "v0.11.0"
  ROOK_VERSION: "v1.6.8"

defaults:
  run:
    shell: 'bash -Eeuo pipefail -x {0}'

jobs:

  duplicate_runs:
    runs-on: ubuntu-20.04
    name: Skip duplicate runs
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip == 'true' && github.ref != 'refs/heads/main' }}
    steps:
      - id: skip_check
        uses: fkirc/skip-duplicate-actions@v3.4.1
        with:
          concurrent_skipping: 'same_content'
          skip_after_successful_duplicate: 'true'
          paths_ignore: '["README.md", "docs/**"]'
          do_not_skip: '["pull_request", "workflow_dispatch", "schedule"]'

  golangci:
    name: Run linters
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.5
      -
        name: Run golangci-lint
        uses: golangci/golangci-lint-action@v2.5.2
        with:
          version: ${{ env.GOLANGCI_LINT_VERSION }}
          args: --timeout 4m

  shellcheck:
    name: Run shellcheck linter
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    env:
        SHELLCHECK_OPTS: -a -S style
    steps:
    -
      uses: actions/checkout@v2.3.5
    -
      name: Run ShellCheck
      uses: ludeeus/action-shellcheck@1.1.0

  tests:
    name: Run unit tests
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.5
      -
        name: Install Go
        uses: actions/setup-go@v2
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      # Install kubebuilder that is a requirement to run tests
      -
        name: Install Kubebuilder
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 30
          max_attempts: 3
          on_retry_command: |
            # Clear-ups before retries
            sudo rm -rf /tmp/kubebuilder/* /usr/local/kubebuilder
          command: |
            mkdir -p /tmp/kubebuilder
            # The doc suggests using go.kubebuilder.io, but the redirects
            # are currently not working there. We get the release directly
            # from github.
            kubebuilder_url="https://github.com/kubernetes-sigs/kubebuilder/releases/download/v${{ env.KUBEBUILDER_VERSION }}/kubebuilder_${{ env.KUBEBUILDER_VERSION }}_$(go env GOOS)_$(go env GOARCH).tar.gz"
            curl -sSL ${kubebuilder_url} | tar --strip-components=1 -xz -C /tmp/kubebuilder
            sudo mv /tmp/kubebuilder /usr/local/
      -
        name: Run unit tests
        run:
          make test

  apidoc:
    name: Verify API doc is up to date
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
    - name: Checkout code
      uses: actions/checkout@v2.3.5

    - name: Install Go
      uses: actions/setup-go@v2.1.3
      with:
        go-version: ${{ env.GOLANG_VERSION }}

    - name: Run make apidoc
      run: |
        make apidoc

    - name: Verify apidoc changes
      run: |
        apidoc_file_path='docs/src/api_reference.md'
        if git status --porcelain $apidoc_file_path | grep '^ M'; then
          echo "The API documentation doesn't reflect the current API. Please run make apidoc."
          exit 1
        fi

  crd:
    name: Verify CRD is up to date
    needs: duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout code
        uses: actions/checkout@v2.3.5

      - name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}

      - name: Run make manifests
        run: |
          make manifests

      - name: Check CRD manifests are up to date
        run: |
          crd_path='config/crd'
          if git status --porcelain $crd_path | grep '^ M'; then
            echo "The CRD manifests do not reflect the current API. Please run make manifests."
            exit 1
          fi

  buildx:
    name: Build containers
    needs:
      - golangci
      - shellcheck
      - tests
      - apidoc
      - crd
      - duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    outputs:
      image: ${{ steps.image-meta.outputs.image }}
    steps:
      -
        name: Checkout
        uses: actions/checkout@v2.3.5
        with:
          # To identify the commit we need the history and all the tags.
          fetch-depth: 0
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name: Build meta
        id: build-meta
        run: |
          images='quay.io/enterprisedb/cloud-native-postgresql-testing'
          tags=''
          labels='quay.expires-after=7d'
          commit_sha=${{ github.event.pull_request.head.sha || github.sha }}
          commit_date=$(git log -1 --pretty=format:'%ad' --date short "${commit_sha}")
          # use git describe to get the nearest tag and use that to build the version (e.g. 1.4.0+dev24 or 1.4.0)
          commit_version=$(git describe --tags --match 'v*' "${commit_sha}"| sed -e 's/^v//; s/-g[0-9a-f]\+$//; s/-\([0-9]\+\)$/+dev\1/')
          commit_short=$(git rev-parse --short "${commit_sha}")
          if [ "${GITHUB_REF#refs/heads/}" == main ]
          then
            images="${images},upmdev.azurecr.io/enterprisedb/cloud-native-postgresql"
          fi
          echo "::set-output name=images::${images}"
          echo "::set-output name=tags::${tags}"
          echo "::set-output name=labels::${labels}"
          echo "::set-output name=date::${commit_date}"
          echo "::set-output name=version::${commit_version}"
          echo "::set-output name=commit::${commit_short}"
      -
        name: Set GoReleaser environment
        run: |
          echo GOPATH=$(go env GOPATH) >> $GITHUB_ENV
          echo PWD=$(pwd) >> $GITHUB_ENV
      -
        name: Run GoReleaser
        uses: goreleaser/goreleaser-action@v2
        with:
          distribution: goreleaser
          version: latest
          args: build -f .goreleaser-multiarch.yml --skip-validate --rm-dist
        env:
          DATE: ${{ steps.build-meta.outputs.date }}
          COMMIT: ${{ steps.build-meta.outputs.commit }}
          VERSION: ${{ steps.build-meta.outputs.version }}
      -
        name: Docker meta
        id: docker-meta
        uses: docker/metadata-action@v3
        with:
          images: ${{ steps.build-meta.outputs.images }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
      -
        name: Detect platforms
        id: docker-platforms
        run: |
          # Available architecture on UBI8 are: linux/amd64, linux/arm64, linux/ppc64le, linux/s390x
          # Keep in mind that adding more platforms (architectures) will increase the building
          # time even if we use the ghcache for the building process.
          platforms="linux/amd64,linux/arm64,linux/ppc64le,linux/s390x"
          echo "::set-output name=platforms::${platforms}"
      -
        name: Set up QEMU
        uses: docker/setup-qemu-action@v1
        with:
          image: tonistiigi/binfmt:qemu-v6.1.0
          platforms: ${{ steps.docker-platforms.outputs.platforms }}
      -
        name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v1
      -
        name: Login to quay.io
        uses: docker/login-action@v1
        with:
          registry: quay.io/enterprisedb
          username: ${{ secrets.QUAY_USERNAME }}
          password: ${{ secrets.QUAY_TOKEN }}
      -
        name: Login to Azure Container Registry
        uses: docker/login-action@v1
        with:
          registry: upmdev.azurecr.io
          username: ${{ secrets.AZURECR_USER }}
          password: ${{ secrets.AZURECR_SECRET }}
      -
        name: Build and push
        uses: docker/build-push-action@v2.7.0
        with:
          platforms: ${{ steps.docker-platforms.outputs.platforms }}
          context: .
          push: true
          build-args: |
            VERSION=${{ steps.build-meta.outputs.version }}
          tags: ${{ steps.docker-meta.outputs.tags }}
          labels: ${{ steps.build-meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      -
        name: Image Meta
        id: image-meta
        env:
          TAGS: ${{ steps.docker-meta.outputs.tags }}
        run: |
          # If there is more than one tag, take the first one
          # TAGS could be separated by newlines or commas
          image=$(sed -n '1{s/,.*//; p}' <<< "$TAGS")
          echo "::set-output name=image::${image}"

  trigger-ocp:
    name: Trigger OCP bundle
    needs:
      - golangci
      - shellcheck
      - tests
      - apidoc
      - crd
      - duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' && github.event.sender.login != 'cnp-autobot' }}
    runs-on: ubuntu-20.04
    steps:
      - name: Repository Dispatch
        uses: peter-evans/repository-dispatch@v1.1.3
        with:
          token: ${{ secrets.REPO_GHA_PAT }}
          repository: enterprisedb/cloud-native-postgresql-ocp-certified
          event-type: cnp-trigger
          client-payload: '{"upstream_commit": "${{ github.event.pull_request.head.sha || github.sha }}"}'

  generate-jobs:
    name: Generate jobs for E2E tests
    needs:
      - buildx
      - duplicate_runs
    if: ${{ needs.duplicate_runs.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    outputs:
      image: ${{ needs.buildx.outputs.image }}
      localMatrix: ${{ steps.generate-jobs.outputs.localMatrix }}
      localEnabled: ${{ steps.generate-jobs.outputs.localEnabled }}
      eksMatrix: ${{ steps.generate-jobs.outputs.eksMatrix }}
      eksEnabled: ${{ steps.generate-jobs.outputs.eksEnabled }}
      aksMatrix: ${{ steps.generate-jobs.outputs.aksMatrix }}
      aksEnabled: ${{ steps.generate-jobs.outputs.aksEnabled }}
      gkeMatrix: ${{ steps.generate-jobs.outputs.gkeMatrix }}
      gkeEnabled: ${{ steps.generate-jobs.outputs.gkeEnabled }}
      rkeMatrix: ${{ steps.generate-jobs.outputs.rkeMatrix }}
      rkeEnabled: ${{ steps.generate-jobs.outputs.rkeEnabled }}
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.5
      -
        id: generate-jobs
        name: Generate Jobs
        shell: bash
        run: |
          python .github/e2e-matrix-generator.py \
            -m '${{ github.event.inputs.depth || github.event_name }}' \
            -l '${{ github.event.inputs.limit }}'

  e2e-local:
    name: Run E2E on local executors
    if: ${{ needs.generate-jobs.outputs.localEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
    needs:
      - generate-jobs
      - duplicate_runs
    strategy:
      fail-fast: false
      matrix: ${{ fromJSON(needs.generate-jobs.outputs.localMatrix) }}
    runs-on: ubuntu-20.04
    env:
      TEST_DEPTH: 4
      K8S_VERSION: "${{ matrix.k8s_version }}"
      POSTGRES_IMG: "${{ matrix.postgres_img }}"
      E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

      DOCKER_SERVER: quay.io/enterprisedb
      DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

      DEBUG: "true"
      BUILD_IMAGE: "false"
      CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
      E2E_DEFAULT_STORAGE_CLASS: standard
      LOG_DIR: ${{ github.workspace }}/kind-logs/
      DOCKER_REGISTRY_MIRROR: https://mirror.gcr.io
    steps:
      -
        name: Cleanup Disk
        uses: curoky/cleanup-disk-action@v2.0
      -
        name: Cleanup docker cache
        run: |
          echo "-------------Disk info before cleanup----------------"
          df -h
          echo "-----------------------------------------------------"
          docker system prune -a -f
          echo "-------------Disk info after cleanup----------------"
          df -h
          echo "-----------------------------------------------------"
      -
        name: Checkout code
        uses: actions/checkout@v2.3.5
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name: Prepare the environment
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 30
          max_attempts: 3
          on_retry_command: |
            # Clear-ups before retries
            rm -rf /usr/local/bin/kind /usr/local/bin/kubectl
          command: |
            sudo apt-get update
            sudo apt-get install -y gettext-base
            sudo hack/setup-cluster.sh prepare /usr/local/bin
      -
        name: Run Kind End-to-End tests
        run:
          make e2e-test-kind
      -
        name: Archive Kind logs
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: kind-logs-${{ matrix.id }}
          path: kind-logs/
          retention-days: 7
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore

  e2e-aks:
    name: Run E2E on Microsoft AKS
    if: ${{ needs.generate-jobs.outputs.aksEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
    needs:
      - generate-jobs
      - duplicate_runs
    strategy:
      fail-fast: false
      max-parallel: 15
      matrix:
        ${{ fromJSON(needs.generate-jobs.outputs.aksMatrix) }}
    runs-on: ubuntu-20.04
    env:
      TEST_DEPTH: 4
      K8S_VERSION: "${{ matrix.k8s_version }}"
      POSTGRES_IMG: "${{ matrix.postgres_img }}"
      E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

      DOCKER_SERVER: quay.io/enterprisedb
      DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

      DEBUG: "true"
      BUILD_IMAGE: "false"
      CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
      E2E_DEFAULT_STORAGE_CLASS: rook-ceph-block

    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.5
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name: Prepare the environment
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 30
          max_attempts: 3
          command: |
            sudo apt-get update
            sudo apt-get install -y gettext-base
      -
        name:  Install ginkgo
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 3
          command: |
            go install github.com/onsi/ginkgo/ginkgo@6e68f79684d4
      -
        name: Azure Login
        uses: azure/login@v1.4.0
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      -
        name: Install kubectl
        uses: azure/setup-kubectl@v1
        with:
          version: v${{ env.K8S_VERSION }}
      -
        name: Create AKS cluster
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 10
          max_attempts: 3
          command: |
            az extension add --name aks-preview
            az account set --subscription "Cloud Native Development"
            az aks create --resource-group ${{ secrets.AZURE_RESOURCEGROUP }} \
              --name ${{ secrets.AZURE_RESOURCENAME }}-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' ) \
              --node-count 3 -k v${K8S_VERSION} --generate-ssh-keys --enable-addons monitoring \
              --workspace-resource-id ${{ secrets.AZURE_WORKSPACE_RESOURCE_ID }} \
              --aks-custom-headers EnableAzureDiskFileCSIDriver=true
            AZURE_STORAGE_ACCOUNT="${{ github.run_number }}$( echo ${{ matrix.id }} | cut -c4- | tr -d '_.-' | tr '[:upper:]' '[:lower:]' )"
            az storage account create \
              --resource-group ${{ secrets.AZURE_RESOURCEGROUP }} \
              --name ${AZURE_STORAGE_ACCOUNT} \
              --sku Standard_LRS -o none
            az aks get-credentials --resource-group ${{ secrets.AZURE_RESOURCEGROUP }} \
              --name ${{ secrets.AZURE_RESOURCENAME }}-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' )

            # get Storage Account credentials
            echo "AZURE_STORAGE_ACCOUNT=${AZURE_STORAGE_ACCOUNT}" >> $GITHUB_ENV
            AZURE_STORAGE_KEY=$(az storage account keys list -g "${{ secrets.AZURE_RESOURCEGROUP }}" -n "${AZURE_STORAGE_ACCOUNT}" --query "[0].value" -o tsv)
            echo "AZURE_STORAGE_KEY=${AZURE_STORAGE_KEY}" >> $GITHUB_ENV
      -
        # Azure is slow in provisioning disks, and we can't wait two minutes
        # every time we create a pod, otherwise all the tests will time out.
        # We set up a few large disks now, we run Rook on top of them and we
        # use rook to get the small PV we use in the tests.
        # It can still take a while to deploy rook.
        name: Set up Rook
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 27
          max_attempts: 1
          command: |
            STORAGECLASSNAME=default
            GO111MODULE=on go get github.com/mikefarah/yq/v4
            ROOK_BASE_URL=https://raw.githubusercontent.com/rook/rook/${{ env.ROOK_VERSION }}/cluster/examples/kubernetes/ceph
            kubectl apply -f ${ROOK_BASE_URL}/crds.yaml
            kubectl apply -f ${ROOK_BASE_URL}/common.yaml
            kubectl apply -f ${ROOK_BASE_URL}/operator.yaml
            curl ${ROOK_BASE_URL}/cluster-on-pvc.yaml | \
              sed '/^ *#/d;/^ *$/d' | \
              yq e ".spec.storage.storageClassDeviceSets[].volumeClaimTemplates[].spec.resources.requests.storage = \"50Gi\" |
                .spec.storage.storageClassDeviceSets[].volumeClaimTemplates[].spec.storageClassName = \"${STORAGECLASSNAME}\" |
                .spec.mon.volumeClaimTemplate.spec.storageClassName = \"${STORAGECLASSNAME}\" " - | \
              kubectl apply -f -
            while true; do
              output=$( kubectl get deploy -n rook-ceph -l app=rook-ceph-osd --no-headers -o name )
              if [[ $(wc -w <<< $output)  == 3 ]]; then
                break
              fi
            done
            echo "Waiting for Rook OSDs to be available"
            kubectl wait deploy -n rook-ceph --for condition=available --timeout 480s -l app=rook-ceph-osd
            kubectl apply -f ${ROOK_BASE_URL}/csi/rbd/storageclass.yaml
      -
        name: Run E2E tests
        run: hack/e2e/run-e2e.sh
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore
      -
        name: Clean up
        if: always()
        uses: azure/CLI@v1
        with:
          inlineScript: |
            az account set --subscription "Cloud Native Development"
            az aks delete --resource-group ${{ secrets.AZURE_RESOURCEGROUP }} -y \
              --name ${{ secrets.AZURE_RESOURCENAME }}-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' )
            az storage account delete -y --resource-group ${{ secrets.AZURE_RESOURCEGROUP }} --name ${{ env.AZURE_STORAGE_ACCOUNT }}

  e2e-eks:
    name: Run E2E on Amazon EKS
    if: ${{ needs.generate-jobs.outputs.eksEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
    needs:
      - generate-jobs
      - duplicate_runs
    strategy:
      fail-fast: false
      matrix:
         ${{ fromJSON(needs.generate-jobs.outputs.eksMatrix) }}
    runs-on: ubuntu-20.04
    env:
      TEST_DEPTH: 4
      K8S_VERSION: "${{ matrix.k8s_version }}"
      POSTGRES_IMG: "${{ matrix.postgres_img }}"
      E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

      DOCKER_SERVER: quay.io/enterprisedb
      DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

      DEBUG: "true"
      BUILD_IMAGE: "false"
      CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
      E2E_DEFAULT_STORAGE_CLASS: gp2

      AWS_REGION: eu-central-1
    steps:
      -
        name: Set cluster name
        run: |
          echo "CLUSTER_NAME=cnp-test-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' )" >> $GITHUB_ENV
      -
        name: Checkout code
        uses: actions/checkout@v2.3.5
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name: Prepare the environment
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 30
          max_attempts: 3
          command: |
            sudo apt-get update
            sudo apt-get install -y gettext-base
      -
        name:  Install ginkgo
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 3
          command: |
            go install github.com/onsi/ginkgo/ginkgo@6e68f79684d4
      -
        name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      -
        name: Install eksctl
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 3
          command: |
            mkdir -p "$HOME/.local/bin"
            curl -sL "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" \
              | tar xz -C $HOME/.local/bin
            echo "$HOME/.local/bin" >> $GITHUB_PATH
      -
        name: Configure EKS setup
        run: |
          envsubst < hack/e2e/eks-cluster.yaml.template > hack/e2e/eks-cluster.yaml
      -
        name: Setup EKS
        run: |
          eksctl create cluster -f hack/e2e/eks-cluster.yaml
      -
        name: Setup log archiving via fluentd and insights
        uses: nick-invision/retry@v2
        with:
          timeout_minutes: 1
          max_attempts: 3
          command: |
            curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluentd-quickstart.yaml \
              | sed "s/{{cluster_name}}/${{ env.CLUSTER_NAME }}/;s/{{region_name}}/${{ env.AWS_REGION }}/" \
              | kubectl apply -f -
      -
        name: Run E2E tests
        run: hack/e2e/run-e2e.sh
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore
      -
        name: Clean up
        if: always()
        run: |
          while true; do
              output=$( eksctl delete cluster -n ${{ env.CLUSTER_NAME }} -r "${{ env.AWS_REGION }}" --wait 2>&1 )
              status=$?
              if [[ $status == 0 ]]; then
                  echo "EKS cluster deleted"
                  break
              fi
              if ( grep "ResourceNotFoundException: No cluster found for name: ${{ env.CLUSTER_NAME }}" <<< "$output" ); then
                  echo "EKS cluster doesn't exist, nothing to remove"
                  break
              fi
              echo "Failed deleting cluster ${{ env.CLUSTER_NAME }}, retrying"
              sleep 5
          done

  e2e-gke:
    name: Run E2E on Google GKE
    if: ${{ needs.generate-jobs.outputs.gkeEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
    needs:
      - generate-jobs
      - duplicate_runs
    strategy:
      fail-fast: false
      max-parallel: 10
      matrix:
        ${{ fromJSON(needs.generate-jobs.outputs.gkeMatrix) }}
    runs-on: ubuntu-20.04
    env:
      TEST_DEPTH: 4
      K8S_VERSION: "${{ matrix.k8s_version }}"
      POSTGRES_IMG: "${{ matrix.postgres_img }}"
      E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

      DOCKER_SERVER: quay.io/enterprisedb
      DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

      DEBUG: "true"
      BUILD_IMAGE: "false"
      CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
      E2E_DEFAULT_STORAGE_CLASS: standard

      ZONE: europe-west3-a
    steps:
      -
        name: Checkout code
        uses: actions/checkout@v2.3.5
      -
        name: Install Go
        uses: actions/setup-go@v2.1.3
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name: Prepare the environment
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 30
          max_attempts: 3
          command: |
            sudo apt-get update
            sudo apt-get install -y gettext-base
      -
        name: Install ginkgo
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 30
          max_attempts: 3
          command: |
            go install github.com/onsi/ginkgo/ginkgo@6e68f79684d4
      -
        name: Set cluster name
        run: |
          # GKE cluster names rules:
          # only lowercase alphanumerics and '-' allowed, must start with a letter and end with an alphanumeric,
          # and must be no longer than 40 characters
          # We need to shorten the name and lower the case
          SHORT_ID=$( echo ${{ matrix.id }} | tr -d '_.-' | tr '[:upper:]' '[:lower:]')
          echo "CLUSTER_NAME=cnp-test-${{ github.run_number }}-${SHORT_ID}" >> $GITHUB_ENV
      -
        name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@master #wokeignore:rule=master
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT }}
          export_default_credentials: true
      -
        name: Install kubectl
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 30
          max_attempts: 3
          command: |
           gcloud components install --quiet kubectl
      -
        name: Create GKE cluster
        run: |
          # We may go over the amount of API requests allowed
          # by Google when creating all the clusters at the same time.
          # We give a few attempts at creating the cluster before giving up
          for i in `seq 1 5`; do
            if gcloud container clusters create ${{ env.CLUSTER_NAME }} \
              --num-nodes=3 \
              --cluster-version=${{ env.K8S_VERSION }} \
              --zone=${{ env.ZONE }} \
              --disk-size=20 \
              --machine-type=e2-standard-2
            then
              exit 0
            fi
            echo "Couldn't create the cluster. Retrying in 100s."
            sleep 100
          done
          echo "Couldn't create the cluster. Failing."
          exit 1
      -
        name: Get GKE kubeconfig credentials
        uses: google-github-actions/get-gke-credentials@main
        with:
          cluster_name: ${{ env.CLUSTER_NAME }}
          location: ${{ env.ZONE }}
          credentials: ${{ secrets.gcp_credentials }}
          use_auth_provider: true
      -
        name: Run E2E tests
        run: hack/e2e/run-e2e.sh
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore
      -
        name: Clean up
        if: always()
        run: |
          gcloud container clusters delete ${{ env.CLUSTER_NAME }} --zone=${{ env.ZONE }} --quiet
          # Disks are not automatically deleted when the cluster is removed and
          # their name only contains the run number, so we can't find the actual cluster from
          # the matrix that created them. We delete all the disks of a run that are not
          # owned by anyone, without worrying to much if some other job deleted them first.
          IDS=$(gcloud compute disks list --filter="name~cnp-test-${{github.run_number}} AND zone:${{env.ZONE}} AND -users:*" --format="value(id)")
          for ID in ${IDS}
          do
            gcloud compute disks delete --zone "${{env.ZONE}}" --quiet "${ID}" || true
          done

  e2e-rke:
      name: Run E2E on Rancher RKE
      if: ${{ needs.generate-jobs.outputs.rkeEnabled == 'true' && needs.duplicate_runs.outputs.should_skip != 'true' }}
      needs:
        - generate-jobs
        - duplicate_runs
      strategy:
        fail-fast: false
        matrix:
          ${{ fromJSON(needs.generate-jobs.outputs.rkeMatrix) }}
      runs-on: ubuntu-20.04
      env:
        TEST_DEPTH: 4
        POSTGRES_IMG: "${{ matrix.postgres_img }}"
        E2E_PRE_ROLLING_UPDATE_IMG: "${{ matrix.postgres_pre_img }}"

        DOCKER_SERVER: quay.io/enterprisedb
        DOCKER_USERNAME: ${{ secrets.QUAY_USERNAME }}
        DOCKER_PASSWORD: ${{ secrets.QUAY_TOKEN }}

        DEBUG: "true"
        BUILD_IMAGE: "false"
        CONTROLLER_IMG: ${{ needs.generate-jobs.outputs.image }}
        E2E_DEFAULT_STORAGE_CLASS: gp2
        LOG_DIR: ${{ github.workspace }}/rke-logs/

        AWS_REGION: eu-central-1
        TF_WORKDIR: ${{ github.workspace }}/hack/e2e/rke-ec2/
        TF_LOG: TRACE
        TF_LOG_PATH: terraform.log
        TF_VAR_k8s_version: "${{ matrix.k8s_version }}"
      steps:
      -
        name: Set cluster name
        run: |
          echo "TF_VAR_cluster_name=cnp-test-${{ github.run_number }}-$( echo ${{ matrix.id }} | tr -d '_.-' )" >> $GITHUB_ENV
      -
        name: Checkout code
        uses: actions/checkout@v2.3.5
      -
        name: Install Go
        uses: actions/setup-go@v2
        with:
          go-version: ${{ env.GOLANG_VERSION }}
      -
        name:  Install ginkgo
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 30
          max_attempts: 3
          command: |
            go install github.com/onsi/ginkgo/ginkgo@6e68f79684d4
      -
        name:  Install Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 0.14.x
      -
        name: Set Docker version
        run: |
          echo "K8S_VERSION=$(echo ${{ env.TF_VAR_k8s_version }} | awk -F '[v -]' '{print $2}')" >> $GITHUB_ENV
          if dpkg --compare-versions "${{ env.K8S_VERSION }}" "lt" "1.17" ]; then
            echo "TF_VAR_docker_install_url=https://releases.rancher.com/install-docker/18.09.sh" >> $GITHUB_ENV
          fi
      -
        name: Set Source Ip Address
        run: |
          # Restrict access to just the source address
          echo "TF_VAR_source_ip_address=$(curl -s showip.net)" >> $GITHUB_ENV
      -
        name: Install kubectl
        uses: azure/setup-kubectl@v1
        with:
          version: v${{ env.K8S_VERSION }}
      -
        name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      -
        name: Terraform RKE cluster
        working-directory: ${{ env.TF_WORKDIR }}
        run: |
          terraform init && terraform apply -auto-approve
          echo "KUBECONFIG=${PWD}/kube_config_cluster.yml" >> $GITHUB_ENV
          # Retrieve the private_key and the list of hosts.
          # They will be used to gather log files
          jq -r '.outputs.id_rsa.value' terraform.tfstate > ${PWD}/id_rsa && chmod 600 ${PWD}/id_rsa
          jq -r '.outputs.public_dns.value[]' terraform.tfstate > ${PWD}/host.list
      -
        name: Run E2E tests
        run: hack/e2e/run-e2e.sh
      -
        name: Wait for PVs to be released
        if: always()
        run: |
          ITER=0
          MAX_ITER=12
          while true; do
            output=$( kubectl get pv -o json | jq '.items | length' 2>&1 )
            if [[ $output == "0" ]]; then
                echo "PVs have been released"
                break
            fi
            (( ++ITER ))
            if [[ ${ITER} -ge ${MAX_ITER} ]]; then
                echo "Time out waiting for Pvs to be terminating"
                exit 1
            fi
            sleep 10;
          done
      -
        name: Gather RKE logs
        if: failure()
        working-directory: ${{ env.TF_WORKDIR }}
        run: |
          # To avoid rsync warnings with vanished files, in case of error we wait and retry
          # after 20 seconds for 3 times. This could happen because some pods created during the E2E
          # tests are still being terminated, and their logs may be removed during the copy.
          for i in $(cat ${PWD}/host.list); do \
            mkdir -p "${LOG_DIR}/${i}"; \
            for x in `seq 1 3`; do
              if rsync -avPL --rsync-path="sudo rsync" -e "ssh -i ${PWD}/id_rsa -l ubuntu -o StrictHostKeyChecking=no" \
                ${i}:/var/log/containers/* "${LOG_DIR}/${i}/"; then
                break
              fi
              echo "Couldn't transfer logs. Trying again in 20s."
              sleep 20
            done
          done
      -
        name: Archive RKE logs
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: rke-logs-${{ matrix.id }}
          path: |
           rke-logs/
           ${{ env.TF_WORKDIR }}/terraform.log
           ${{ env.TF_WORKDIR }}/rke_debug.log
          retention-days: 7
      -
        name: Archive e2e failure contexts
        if: failure()
        uses: actions/upload-artifact@v2
        with:
          name: test-failure-contexts-${{ matrix.id }}
          path: |
            tests/*/out/
          retention-days: 7
          if-no-files-found: ignore
      -
        name: Clean up
        if: always()
        working-directory: ${{ env.TF_WORKDIR }}
        run: |
          terraform destroy -auto-approve
          rm -fr .terraform* terraform* id_rsa host.list
