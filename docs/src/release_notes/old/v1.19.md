---
id: v1.19
title: Release notes for CloudNativePG 1.19
---

# Release notes for CloudNativePG 1.19

History of user-visible changes in the 1.19 minor release of CloudNativePG.

For a complete list of changes, please refer to the
[commits](https://github.com/cloudnative-pg/cloudnative-pg/commits/release-1.19)
on the release branch in GitHub.

## Version 1.19.6

**Release date:** Nov 3, 2023

:::warning
    This is expected to be the last release in the 1.19.X series.
    Users are encouraged to update to a newer minor version soon.
:::

Enhancements:

- Enhance the `status` command of the `cnpg` plugin for `kubectl` with progress
  information on active streaming base backups (#3101)
- Allow the configuration of `max_prepared_statements` with the pgBouncer
  `Pooler` resource (#3174)

Fixes:

- Suspend WAL archiving during a switchover and resume it when it is completed
  (#3227)
- Ensure that the instance manager always uses `synchronous_commit = local`
  when managing the PostgreSQL cluster (#3143)
- Custom certificates for streaming replication user through
  `.spec.certificates.replicationTLSSecret` are now working (#3209)
- Set the `cnpg.io/cluster` label to the `Pooler` pods (#3153)

Changes:

- Stop using the `postgresql.auto.conf` file inside PGDATA to control Postgres
  replication settings, and replace it with a file named `override.conf`(#2812)

Technical enhancements:

- Use extended query protocol for PostgreSQL in the instance manager (#3152)

## Version 1.19.5

**Release date:** Oct 11, 2023

:::warning
    Version 1.19 will reach its End-of-Life (EOL) on November 9, 2023.
    If you haven't done it yet, please start planning an upgrade
    as soon as possible.
:::

Important Changes:

- Change the default value of `stopDelay` to 1800 seconds instead of 30 seconds
  (#2848)
- Introduce a new parameter, called `smartShutdownTimeout`, to control the
  window of time reserved for the smart shutdown of Postgres to complete; the
  general formula to compute the overall timeout to stop Postgres is
  `max(stopDelay -  smartShutdownTimeout, 30)` (#2848)
- Change the default value of `startDelay` to 3600, instead of 30 seconds
  (#2847)
- Replace the livenessProbe initial delay with a more proper Kubernetes
  startup probe to deal with the start of a Postgres server (#2847)
- Change the default value of `switchoverDelay` to 3600 seconds instead of
  40000000 seconds (#2846)
- Stop supporting the `postgresql` label - replaced by `cnpg.io/cluster` in
  1.18 (#2744)

Security:

- Add a default `seccompProfile` to the operator deployment (#2926)

Enhancements:

- Introduce the `cnpg.io/coredumpFilter` annotation to control the content of a
  core dump generated in the unlikely event of a PostgreSQL crash, by default
  set to exclude shared memory segments from the dump (#2733)
- Allow to configure ephemeral-storage limits for the shared memory and
  temporary data ephemeral volumes (#2830)
- Validate resource limits and requests through the webhook (#2663)
- Ensure that PostgreSQL's `shared_buffers` are coherent with the pods'
  allocated memory resources (#2840)
- Add `uri` and `jdbc-uri` fields in the credential secrets to facilitate
  developers when connecting their applications to the database (#2186)
- Add a new phase `Waiting for the instances to become active` for finer
  control of a cluster's state waiting for the replicas to be ready (#2612)
- Improve detection of Pod rollout conditions through the `podSpec` annotation
  (#2243)
- Add primary timestamp and uptime to the kubectl plugin's `status` command
  (#2953)

Fixes:

- Ensure that the primary instance is always recreated first by prioritizing
  ready PVCs with a primary role (#2544)
- Honor the `cnpg.io/skipEmptyWalArchiveCheck` annotation during recovery to
  bypass the check for an empty WAL archive (#2731)
- Prevent a cluster from being stuck when the PostgreSQL server is down but the
  pod is up on the primary (#2966)
- Avoid treating the designated primary in a replica cluster as a regular HA
  replica when replication slots are enabled (#2960)
- Reconcile services every time the selectors change or when labels/annotations
  need to be changed (#2918)
- Defaults to `app` both the owner and database during recovery bootstrap
  (#2957)
- Avoid write-read concurrency on cached cluster (#2884)
- Remove empty items, make them unique and sort in the `ResourceName` sections
  of the generated roles (#2875)
- Ensure that the `ContinuousArchiving` condition is properly set to 'failed'
  in case of errors (#2625)
- Make the `Backup` resource reconciliation cycle more resilient on
  interruptions by stopping only if the backup is completed or failed (#2591)
- Reconcile PodMonitor `labels` and `annotations` (#2583)
- Fix backup failure due to missing RBAC `resourceNames` on the `Role` object
  (#2956)
- Observability:

    - Add TCP port label to default `pg_stat_replication` metric (#2961)
    - Fix the `pg_wal_stat` default metric for Prometheus (#2569)
    - Improve the `pg_replication` default metric for Prometheus (#2744 and
      #2750)
    - Use `alertInstanceLabelFilter` instead of `alertName` in the provided
      Grafana dashboard
    - Enforce `standard_conforming_strings` in metric collection (#2888)

Changes:

- Set the default operand image to PostgreSQL 16.0
- Fencing now uses PostgreSQL's fast shutdown instead of smart shutdown to halt
  an instance (#3051)
- Rename webhooks from kb.io to cnpg.io group (#2851)
- Let the `cnpg hibernate` plugin command use the
  `ClusterManifestAnnotationName` and `PgControldataAnnotationName` annotations
  on PVCs (#2657)
- Add the `cnpg.io/instanceRole` label while deprecating the existing `role`
  label (#2915)

Technical enhancements:

- Replace `k8s-api-docgen` with `gen-crd-api-reference-docs` to automatically
  build the API reference documentation (#2606)

## Version 1.19.4

**Release date:** July 27, 2023

Enhancements:

- New `logs` command in the kubectl plugin, to retrieve or follow the logs
  of all pods in a cluster (#2375)
- Add support for specifying priorityClassName in pods, helping Kubernetes
  make scheduling decisions (#2043)
- Add a metric and status field to monitor node usage by a CloudNativePG cluster (#2257)
- Various enhancements to the documentation:
    - Add troubleshooting instructions relating to hugepages (#1390)
    - Extend the FAQs page (#2344)

Technical enhancements:

- Add a check at the start of the restore process to ensure it can proceed; give
  improved error diagnostics if it cannot (#2419)

Fixes:

- Ensure the logic of setting the recovery target matches that of Postgres (#2460)
- Prevent taking over service accounts not owned by the cluster, by setting
  ownerMetadata only during service account creation (#2462)
- Ensure correct permissions of the PGDATA directory for initdb and restore (#2384)
- Prevent a possible crash of the instance manager during the configuration reload (#2393)
- Prevent the LastFailedArchiveTime alert from triggering if a new backup has been
  successful after the failed ones (#1751)
- Prevent services from targeting non-instance pods (#2336)

Security:

- Updated all project dependencies to the latest versions

## Version 1.19.3

**Release date:** June 12, 2023

Enhancements:

- Add the `snapshot` command to the `cnpg` plugin to create a consistent cold
  backup of the cluster from a standby using the Kubernetes `VolumeSnapshot`
  standard resource (#1960)
- First implementation of recovery from a set of CSI VolumeSnapshot resources
  via the `.spec.bootstrap.recovery.volumeSnapshot` stanza (#1960)
- Add `pg_failover_slots` to managed extensions (#2057)
- Improved Grafana dashboard with updated instructions in the documentation and
  the quickstart guide (#1916)
- Introduce the `schemaOnly` option in the `import` stanza, to avoid exporting
  and importing data when you bootstrap a new Postgres Cluster from one or more
  existing databases (#2234)
- Add support for TopologySpreadConstraints to manage scheduling of instance
  pods (#2202)
- Add `PodMonitor` support to the `Pooler`for PgBouncer (#2034)
- Add option to override the default Kubernetes scheduler (#2013)
- Allow configuration of deployment strategy of a `Pooler` resource (#1983)
- Update default PostgreSQL version to 15.3 (#2022)
- Use PgBouncer 1.19 by default (#2018)

Technical enhancements:

- Updated k8s kind tested versions (#2054)
- Use separate transactions to reconcile role credentials. Before this patch,
  the operator would revert the synchronization of all roles if one failed
  (#2004)
- Ensure fencing is removed during cluster restore (#1987)
- Improve logging when deleting Pods (#2136)

Fixes:

- Fix unbound variable with k3d engine which could prevent setup on k3d (#2157)
- Report the correct PG version in the metrics (#2126)
- Use the correct walStorage key in the documentation (#2140)
- Halt reconciliation when the operator cannot connect with the instances, and
  provide a clear diagnostic on such occasions. This will help clarify cases
  where network issues obstruct normal operation of CloudNativePG (#2145),
  (#2233), and (#2242)

## Version 1.19.2

**Release date:** April 27, 2023

Enhancements:

- Improve the `--logs` option of the `report` command of the `cnpg` plugin for
  `kubectl` to also include the previous logs where available (#1811)
- The `-any` service is now disabled by default (#1755)

Security:

- Enable customization of `SeccompProfile` through override via a local file (#1827)

Fixes:

- Apply the PostgreSQL configuration provided by the user during the `initdb`
  bootstrap phase, before the server is started the first time (#1858)

## Version 1.19.1

**Release date:** March 20, 2023

Enhancements:

- Allow overriding the default backup target policy (#1602): previously, all
  backups and scheduled backups would use the cluster-level target policy
- Extend the `debug` cluster's log level to the `initdb` job (#1503)
- Support IPv6 and custom `pg_hba` for the PgBouncer pooler (#1395)
- Enhance observability of backups with two new metrics and additional
  information in the status (#1428)
- Document API calls from the instance manager (#1641)
- Clarify deployment name via Helm (#1505)
- Add the `psql` command to the `cnpg` plugin for `kubectl` (#1668) allowing
  the user to start a `psql` session with a pod (the primary by default)

Technical enhancements:

- Adopt Renovate for dependency tracking/updating (#1367, #1473)
- Inject binaries for all supported architectures in the operator image (#1513)
- Use the backup name to match resources in the backup object store (#1650)
  Leverages the `--name` option introduced with Barman 3.3 to make the
  association between backups and the object store more robust.

Fixes:

- Prevent panic with error handling in the probes (#1716)
- Ensure that the HTTP package and controller runtime logs are in JSON format (#1442)
- Adds WAL storage to a cluster in a single instance Cluster (#1570)
- Various improvements to make backup code more robust (#1536, #1564, #1588, #1466,  #1647)
- Properly show WAL archiving information with `status` command of the `cnpg` plugin (#1666)
- Ensure `nodeAffinity` is applied even if `AdditionalPodAffinity` and
  `AdditionalPodAntiAffinity` are not set (#1663)
- Introduce failover delay during OnlineUpgrading phase (#1728)
  Previously, the online upgrade process could trigger failover logic
  unnecessarily.

## Version 1.19.0

**Release date:** Feb 14, 2023

Important announcements:

- PostgreSQL version 10 is no longer supported as it has reached its EOL.
  Versions 11 and newer are supported. Please plan your migration to
  PostgreSQL 15 as soon as possible. Refer to
  ["Importing Postgres databases"](https://cloudnative-pg.io/docs/devel/database_import/)
  for more information on PostgreSQL major offline upgrades.

Features:

- Backup from a standby: introduce the `.spec.backup.target` option accepting
  that when set to `prefer-standby` will run take the physical base backup from
  the most aligned replica (#1162)
- Delayed failover: introduce the `failoverDelay` parameter to delay the
  failover process once the primary has been detected unhealthy (#1366)

Enhancements:

- Introduce support for Kubernetes' projected volumes (#1269)
- Introduce support custom environment variables for finer control of the
  PostgreSQL server process (#1275)
- Introduce the `backup` command in the `cnpg` plugin for `kubectl` to
  issue a new base backup of the cluster (#1348)
- Improve support for the separate WAL volume feature by enabling users to move
  WAL files to a dedicated volume on an existing Postgres cluster (#1066)
- Enhance WAL observability with additional metrics for the Prometheus
  exporter, including values equivalent to the `min_wal_size`, `max_wal_size`,
  `keep_wal_size`, `wal_keep_segments`, as well as the maximum number of WALs
  that can be stored in the dedicated volume (#1382)
- Add a database comment on the `streaming_replica` user (#1349)
- Document the firewall issues with webhooks on GKE (#1364)
- Add note about postgresql.conf in `recovery` (#1211)
- Add instructions on installing plugin using packages (#1357)
- Specify Postgres versions supported by each minor release (#1355)
- Clarify the meaning of PVC group in CloudNativePG (#1344)
- Add an example of the DigitalOcean S3-compatible Spaces (#1289)
- Update default PostgreSQL version for new cluster definitions to 15.2 (#1430)
- Cover the Kubernetes layer in greater detail in the Architecture
  documentation (#1432)

Technical enhancements:

- Added daily end-to-end smoke test for release branches (#1235)

Fixes:

- Skip executing a `CHECKPOINT` as the `streaming_replica` user (#1408)
- Make `waitForWalArchiveWorking` resilient to connection errors (#1399)
- Ensure that the PVC roles are always consistent (#1380)
- Permit `walStorage` resize when using `pvcTemplate` (#1315)
- Ensure `ExecCommand` obeys timeout (#1242)
- Avoid `PodMonitor` reconcile if Prometheus is not installed (#1238)
- Avoid looking for `PodMonitor` when not needed (#1213)
