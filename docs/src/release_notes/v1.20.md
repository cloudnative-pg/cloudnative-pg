# Release notes for CloudNativePG 1.20

History of user-visible changes in the 1.20 minor release of CloudNativePG.

For a complete list of changes, please refer to the
[commits](https://github.com/cloudnative-pg/cloudnative-pg/commits/release-1.20)
on the release branch in GitHub.

## Version 1.20.3

**Release date:** Oct 11, 2023

Important Changes:

- Change the default value of `stopDelay` to 1800 seconds instead of 30 seconds
  (#2848)
- Introduce a new parameter, called `smartShutdownTimeout`, to control the
  window of time reserved for the smart shutdown of Postgres to complete; the
  general formula to compute the overall timeout to stop Postgres is
  `max(stopDelay -  smartShutdownTimeout, 30)` (#2848)
- Change the default value of `startDelay` to 3600, instead of 30 seconds
  (#2847)
- Replace the livenessProbe initial delay with a more proper Kubernetes
  startup probe to deal with the start of a Postgres server (#2847)
- Change the default value of `switchoverDelay` to 3600 seconds instead of
  40000000 seconds (#2846)
- Stop supporting the `postgresql` label - replaced by `cnpg.io/cluster` in
  1.18 (#2744)

Security:

- Add a default `seccompProfile` to the operator deployment (#2926)

Enhancements:

- Introduce the `cnpg.io/coredumpFilter` annotation to control the content of a
  core dump generated in the unlikely event of a PostgreSQL crash, by default
  set to exclude shared memory segments from the dump (#2733)
- Allow to configure ephemeral-storage limits for the shared memory and
  temporary data ephemeral volumes (#2830)
- Validate resource limits and requests through the webhook (#2663)
- Ensure that PostgreSQL's `shared_buffers` are coherent with the pods'
  allocated memory resources (#2840)
- Add `uri` and `jdbc-uri` fields in the credential secrets to facilitate
  developers when connecting their applications to the database (#2186)
- Add a new phase `Waiting for the instances to become active` for finer
  control of a cluster's state waiting for the replicas to be ready (#2612)
- Improve detection of Pod rollout conditions through the `podSpec` annotation
  (#2243)
- Add primary timestamp and uptime to the kubectl plugin’s `status` command
  (#2953)

Fixes:

- Ensure that the primary instance is always recreated first by prioritizing
  ready PVCs with a primary role (#2544)
- Honor the `cnpg.io/skipEmptyWalArchiveCheck` annotation during recovery to
  bypass the check for an empty WAL archive (#2731)
- Prevent a cluster from being stuck when the PostgreSQL server is down but the
  pod is up on the primary (#2966)
- Avoid treating the designated primary in a replica cluster as a regular HA
  replica when replication slots are enabled (#2960)
- Reconcile services every time the selectors change or when labels/annotations
  need to be changed (#2918)
- Defaults to `app` both the owner and database during recovery bootstrap
  (#2957)
- Avoid write-read concurrency on cached cluster (#2884)
- Remove empty items, make them unique and sort in the `ResourceName` sections
  of the generated roles (#2875)
- Ensure that the `ContinuousArchiving` condition is properly set to 'failed'
  in case of errors (#2625)
- Make the `Backup` resource reconciliation cycle more resilient on
  interruptions by stopping only if the backup is completed or failed (#2591)
- Reconcile PodMonitor `labels` and `annotations` (#2583)
- Fix backup failure due to missing RBAC `resourceNames` on the `Role` object
  (#2956)
- Observability:

    - Add TCP port label to default `pg_stat_replication` metric (#2961)
    - Fix the `pg_wal_stat` default metric for Prometheus (#2569)
    - Improve the `pg_replication` default metric for Prometheus (#2744 and
      #2750)
    - Use `alertInstanceLabelFilter` instead of `alertName` in the provided
      Grafana dashboard
    - Enforce `standard_conforming_strings` in metric collection (#2888)

Changes:

- Set the default operand image to PostgreSQL 16.0
- Fencing now uses PostgreSQL’s fast shutdown instead of smart shutdown to halt
  an instance (#3051)
- Rename webhooks from kb.io to cnpg.io group (#2851)
- Replace the `cnpg snapshot` command with `cnpg backup -m volumeSnapshot` for
  the `kubectl` plugin
- Let the `cnpg hibernate` plugin command use the
  `ClusterManifestAnnotationName` and `PgControldataAnnotationName` annotations
  on PVCs (#2657)
- Add the `cnpg.io/instanceRole` label while deprecating the existing `role`
  label (#2915)

Technical enhancements:

- Replace `k8s-api-docgen` with `gen-crd-api-reference-docs` to automatically
  build the API reference documentation (#2606)


## Version 1.20.2

**Release date:** July 27, 2023

Enhancements:

- New `logs` command in the kubectl plugin, to retrieve or follow the logs
  of all pods in a cluster (#2375)
- Add support for specifying priorityClassName in pods, helping Kubernetes
  make scheduling decisions (#2043)
- Add a metric and status field to monitor node usage by a CloudNativePG cluster (#2257)
- Various enhancements to the documentation:
    - Add troubleshooting instructions relating to hugepages (#1390)
    - Extend the FAQs page (#2344)

Technical enhancements:

- Add a check at the start of the restore process to ensure it can proceed; give
  improved error diagnostics if it cannot (#2419)
- Improve handling of non-expiring passwords in managed roles (#2334)

Fixes:

- Ensure the logic of setting the recovery target matches that of Postgres (#2460)
- Prevent taking over service accounts not owned by the cluster, by setting
  ownerMetadata only during service account creation (#2462)
- Ensure correct permissions of the PGDATA directory for initdb and restore (#2384)
- Prevent a possible crash of the instance manager during the configuration reload (#2393)
- Prevent the LastFailedArchiveTime alert from triggering if a new backup has been
  successful after the failed ones (#1751)
- Prevent services from targeting non-instance pods (#2336)

Security:

- Updated all project dependencies to the latest versions

## Version 1.20.1

**Release date:** June 12, 2023

Enhancements:

- Add the `snapshot` command to the `cnpg` plugin to create a consistent cold
  backup of the cluster from a standby using the Kubernetes `VolumeSnapshot`
  standard resource (#1960)
- First implementation of recovery from a set of CSI VolumeSnapshot resources
  via the `.spec.bootstrap.recovery.volumeSnapshot` stanza (#1960)
- Add `pg_failover_slots` to managed extensions (#2057)
- Improved Grafana dashboard with updated instructions in the documentation and
  the quickstart guide (#1916)
- Introduce the `schemaOnly` option in the `import` stanza, to avoid exporting
  and importing data when you bootstrap a new Postgres Cluster from one or more
  existing databases (#2234)
- Add support for TopologySpreadConstraints to manage scheduling of instance
  pods (#2202)
- Add `PodMonitor` support to the `Pooler`for PgBouncer (#2034)
- Add option to override the default Kubernetes scheduler (#2013)
- Allow configuration of deployment strategy of a `Pooler` resource (#1983)
- Update default PostgreSQL version to 15.3 (#2022)
- Use PgBouncer 1.19 by default (#2018)

Technical enhancements:

- Updated k8s kind tested versions (#2054)
- Declarative roles should ignore passwords if not set, easing management of
  previously existing roles  (#2029)
- Use separate transactions to reconcile role credentials. Before this patch,
  the operator would revert the synchronization of all roles if one failed
  (#2004)
- Ensure fencing is removed during cluster restore (#1987)
- Improve logging when deleting Pods (#2136)

Fixes:

- Fix unbound variable with k3s engine which could prevent setup on K3’s (#2157)
- Report the correct PG version in the metrics (#2126)
- Use the correct walStorage key in the documentation (#2140)
- Halt reconciliation when the operator cannot connect with the instances, and
  provide a clear diagnostic on such occasions. This will help clarify cases
  where network issues obstruct normal operation of CloudNativePG (#2145),
  (#2233), and (#2242)

## Version 1.20.0

**Release date:** April 27, 2023

!!! Important "Important changes from previous versions"
    CloudNativePG 1.20 introduces some changes to the default behavior of a
    few features for newly created `Cluster` resources, compared to previous
    versions of the operator. The goal of these changes is to improve the
    resilience of a Postgres cluster out of the box through convention over
    configuration. For clusters with one or more replicas:
    
      - Backup from standby is now enabled by default, unless `target` is
        explicitly set to `primary`
      - Restart of the primary is now the default method to complete the
        unsupervised rolling update procedure (`primaryUpdateMethod`
        defaults to `restart`, unless explicitly set to `switchover`)
    
    For further information, please refer to the
    ["Installation and upgrades" section](../installation_upgrade.md#upgrading-to-120-from-a-previous-minor-version).

Features:

- **Declarative role management:** introduce the `managed.roles` stanza in the
  `Cluster` spec to provide full lifecycle management of database roles, by
  providing an abstraction to the related DDL commands in PostgreSQL, such as
  `CREATE ROLE` and `ALTER ROLE` (#1524, #1793 and #1815)
- **Declarative hibernation of a PostgreSQL cluster:** introduce a new
  annotation called `cnpg.io/hibernation` to declaratively hibernate a
  PostgreSQL cluster by deleting all pods and keeping the PVCs only; the feature
  also implements the inverse procedure (#1657)

Enhancements:

- Improve the `--logs` option of the `report` command of the `cnpg` plugin for
  `kubectl` to also include the previous logs where available (#1811)
- The `-any` service is now disabled by default (#1755)

Security:

- Enable customization of `SeccompProfile` through override via a local file (#1827)

Fixes:

- Apply the PostgreSQL configuration provided by the user during the `initdb`
  bootstrap phase, before the server is started the first time (#1858)
